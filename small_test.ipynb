{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b98181/miniconda3/envs/new_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils.config import automl_config\n",
    "import numpy as np\n",
    "from utils.callbacks import Verbose\n",
    "from dataset.dataloader import LoadDataLoader\n",
    "from dragon.utils.tools import logger\n",
    "from utils.trainer import Trainer\n",
    "\n",
    "config = automl_config\n",
    "config['filename'] = 'dataset/data.csv'\n",
    "config['target'] = 'conso_rte'\n",
    "config['FeaturesCallbacks'].append(Verbose(logger))\n",
    "config['WeightsCallbacks'].append(Verbose(logger))\n",
    "config['Complexity'] = 2\n",
    "data_loader = LoadDataLoader(config)\n",
    "# Number of epochs to train the features\n",
    "config['MaxFeaturesEpochs'] = 2\n",
    "sp = config['SearchSpace'](config)\n",
    "trainer = Trainer(data_loader)\n",
    "trainer.labels = [e.label for e in sp]\n",
    "# Number of epochs to train the models weights\n",
    "trainer.config['Ep'] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We randomly generate and train models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = sp.random(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  [4.217023755985103, -5.138063081102331, 6.356021228389185, -9.899368832226772, -0.42845572552704425, 8.848729649832418, -3.8668241807026575, 5.928901289835567, -2.5506583386413944, -2.2099051037474604, 7.679412491982735, 3.851132521837087, 5.0670426967131394, 3.3256320659191516, 5.267621224694533, -4.857042557486206, -5.391524490053583]\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: dataset/save/figures/small_example_1 Pages: 1 -->\n",
       "<svg width=\"568pt\" height=\"476pt\"\n",
       " viewBox=\"0.00 0.00 567.50 476.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 472)\">\n",
       "<title>dataset/save/figures/small_example_1</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-472 563.5,-472 563.5,4 -4,4\"/>\n",
       "<!-- Input Features -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>Input Features</title>\n",
       "<path fill=\"#7a5195\" stroke=\"#000000\" d=\"M444,-468C444,-468 304,-468 304,-468 298,-468 292,-462 292,-456 292,-456 292,-444 292,-444 292,-438 298,-432 304,-432 304,-432 444,-432 444,-432 450,-432 456,-438 456,-444 456,-444 456,-456 456,-456 456,-462 450,-468 444,-468\"/>\n",
       "<text text-anchor=\"middle\" x=\"374\" y=\"-445\" font-family=\"sans-serif\" font-size=\"20.00\" fill=\"#ececec\">Input Features</text>\n",
       "</g>\n",
       "<!-- mul,Dropout,0.699058532543122,LeakyReLU -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>mul,Dropout,0.699058532543122,LeakyReLU</title>\n",
       "<path fill=\"#ffa600\" stroke=\"#000000\" d=\"M468,-396C468,-396 12,-396 12,-396 6,-396 0,-390 0,-384 0,-384 0,-372 0,-372 0,-366 6,-360 12,-360 12,-360 468,-360 468,-360 474,-360 480,-366 480,-372 480,-372 480,-384 480,-384 480,-390 474,-396 468,-396\"/>\n",
       "<text text-anchor=\"middle\" x=\"240\" y=\"-373\" font-family=\"sans-serif\" font-size=\"20.00\" fill=\"#000000\">mul,Dropout,0.699058532543122,LeakyReLU</text>\n",
       "</g>\n",
       "<!-- Input Features&#45;&gt;mul,Dropout,0.699058532543122,LeakyReLU -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>Input Features&#45;&gt;mul,Dropout,0.699058532543122,LeakyReLU</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M340.1861,-431.8314C322.7293,-422.4516 301.2513,-410.9112 282.6648,-400.9244\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"284.2686,-397.8129 273.803,-396.1628 280.9554,-403.9792 284.2686,-397.8129\"/>\n",
       "</g>\n",
       "<!-- add,Conv2d,1,35,same,LeakyReLU -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>add,Conv2d,1,35,same,LeakyReLU</title>\n",
       "<path fill=\"#ffa600\" stroke=\"#000000\" d=\"M547.5,-324C547.5,-324 200.5,-324 200.5,-324 194.5,-324 188.5,-318 188.5,-312 188.5,-312 188.5,-300 188.5,-300 188.5,-294 194.5,-288 200.5,-288 200.5,-288 547.5,-288 547.5,-288 553.5,-288 559.5,-294 559.5,-300 559.5,-300 559.5,-312 559.5,-312 559.5,-318 553.5,-324 547.5,-324\"/>\n",
       "<text text-anchor=\"middle\" x=\"374\" y=\"-301\" font-family=\"sans-serif\" font-size=\"20.00\" fill=\"#000000\">add,Conv2d,1,35,same,LeakyReLU</text>\n",
       "</g>\n",
       "<!-- Input Features&#45;&gt;add,Conv2d,1,35,same,LeakyReLU -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>Input Features&#45;&gt;add,Conv2d,1,35,same,LeakyReLU</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M444.1299,-431.9239C461.7518,-423.885 478.5929,-412.3841 489,-396 497.5788,-382.4943 497.5788,-373.5057 489,-360 480.3816,-346.4319 467.3509,-336.2126 453.1183,-328.5352\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"454.6436,-325.3848 444.1299,-324.0761 451.5326,-331.6556 454.6436,-325.3848\"/>\n",
       "</g>\n",
       "<!-- mul,Dropout,0.699058532543122,LeakyReLU&#45;&gt;add,Conv2d,1,35,same,LeakyReLU -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>mul,Dropout,0.699058532543122,LeakyReLU&#45;&gt;add,Conv2d,1,35,same,LeakyReLU</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M273.8139,-359.8314C291.2707,-350.4516 312.7487,-338.9112 331.3352,-328.9244\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"333.0446,-331.9792 340.197,-324.1628 329.7314,-325.8129 333.0446,-331.9792\"/>\n",
       "</g>\n",
       "<!-- Flatten -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>Flatten</title>\n",
       "<path fill=\"#ef5675\" stroke=\"#000000\" d=\"M406.5,-252C406.5,-252 341.5,-252 341.5,-252 335.5,-252 329.5,-246 329.5,-240 329.5,-240 329.5,-228 329.5,-228 329.5,-222 335.5,-216 341.5,-216 341.5,-216 406.5,-216 406.5,-216 412.5,-216 418.5,-222 418.5,-228 418.5,-228 418.5,-240 418.5,-240 418.5,-246 412.5,-252 406.5,-252\"/>\n",
       "<text text-anchor=\"middle\" x=\"374\" y=\"-229\" font-family=\"sans-serif\" font-size=\"20.00\" fill=\"#ececec\">Flatten</text>\n",
       "</g>\n",
       "<!-- add,Conv2d,1,35,same,LeakyReLU&#45;&gt;Flatten -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>add,Conv2d,1,35,same,LeakyReLU&#45;&gt;Flatten</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M374,-287.8314C374,-280.131 374,-270.9743 374,-262.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"377.5001,-262.4132 374,-252.4133 370.5001,-262.4133 377.5001,-262.4132\"/>\n",
       "</g>\n",
       "<!-- concat,Attention1D,1,random,113,Identity -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>concat,Attention1D,1,random,113,Identity</title>\n",
       "<path fill=\"#ffa600\" stroke=\"#000000\" d=\"M461,-180C461,-180 33,-180 33,-180 27,-180 21,-174 21,-168 21,-168 21,-156 21,-156 21,-150 27,-144 33,-144 33,-144 461,-144 461,-144 467,-144 473,-150 473,-156 473,-156 473,-168 473,-168 473,-174 467,-180 461,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"247\" y=\"-157\" font-family=\"sans-serif\" font-size=\"20.00\" fill=\"#000000\">concat,Attention1D,1,random,113,Identity</text>\n",
       "</g>\n",
       "<!-- Flatten&#45;&gt;concat,Attention1D,1,random,113,Identity -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>Flatten&#45;&gt;concat,Attention1D,1,random,113,Identity</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M341.9525,-215.8314C325.558,-206.5368 305.4214,-195.1208 287.9171,-185.1971\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"289.4626,-182.05 279.0372,-180.1628 286.0103,-188.1395 289.4626,-182.05\"/>\n",
       "</g>\n",
       "<!-- mul,Identity,SiLU -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>mul,Identity,SiLU</title>\n",
       "<path fill=\"#ffa600\" stroke=\"#000000\" d=\"M457.5,-108C457.5,-108 290.5,-108 290.5,-108 284.5,-108 278.5,-102 278.5,-96 278.5,-96 278.5,-84 278.5,-84 278.5,-78 284.5,-72 290.5,-72 290.5,-72 457.5,-72 457.5,-72 463.5,-72 469.5,-78 469.5,-84 469.5,-84 469.5,-96 469.5,-96 469.5,-102 463.5,-108 457.5,-108\"/>\n",
       "<text text-anchor=\"middle\" x=\"374\" y=\"-85\" font-family=\"sans-serif\" font-size=\"20.00\" fill=\"#000000\">mul,Identity,SiLU</text>\n",
       "</g>\n",
       "<!-- Flatten&#45;&gt;mul,Identity,SiLU -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>Flatten&#45;&gt;mul,Identity,SiLU</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M418.5227,-223.7495C441.7338,-215.9012 468.1136,-202.4687 482,-180 490.4117,-166.3896 490.4117,-157.6104 482,-144 473.7278,-130.6153 461.0222,-120.4372 447.194,-112.7361\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"448.4771,-109.4611 437.9801,-108.0241 445.2899,-115.6935 448.4771,-109.4611\"/>\n",
       "</g>\n",
       "<!-- concat,Attention1D,1,random,113,Identity&#45;&gt;mul,Identity,SiLU -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>concat,Attention1D,1,random,113,Identity&#45;&gt;mul,Identity,SiLU</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M279.0475,-143.8314C295.442,-134.5368 315.5786,-123.1208 333.0829,-113.1971\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"334.9897,-116.1395 341.9628,-108.1628 331.5374,-110.05 334.9897,-116.1395\"/>\n",
       "</g>\n",
       "<!-- MLP,48,Identity() -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>MLP,48,Identity()</title>\n",
       "<path fill=\"#ef5675\" stroke=\"#000000\" d=\"M457.5,-36C457.5,-36 290.5,-36 290.5,-36 284.5,-36 278.5,-30 278.5,-24 278.5,-24 278.5,-12 278.5,-12 278.5,-6 284.5,0 290.5,0 290.5,0 457.5,0 457.5,0 463.5,0 469.5,-6 469.5,-12 469.5,-12 469.5,-24 469.5,-24 469.5,-30 463.5,-36 457.5,-36\"/>\n",
       "<text text-anchor=\"middle\" x=\"374\" y=\"-13\" font-family=\"sans-serif\" font-size=\"20.00\" fill=\"#ececec\">MLP,48,Identity()</text>\n",
       "</g>\n",
       "<!-- mul,Identity,SiLU&#45;&gt;MLP,48,Identity() -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>mul,Identity,SiLU&#45;&gt;MLP,48,Identity()</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M374,-71.8314C374,-64.131 374,-54.9743 374,-46.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"377.5001,-46.4132 374,-36.4133 370.5001,-46.4133 377.5001,-46.4132\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f6c64654910>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dragon.utils.plot_functions import draw_graph, get_name_features, str_operations\n",
    "m = models[1]\n",
    "features = get_name_features(m[0], automl_config)\n",
    "print(\"Features: \", features)\n",
    "m1 = m[1].matrix\n",
    "n1 = str_operations(m[1].operations)\n",
    "m2 = m[2].matrix\n",
    "n2 = str_operations(m[2].operations)\n",
    "\n",
    "G = draw_graph(n1, m1, n2, m2, \"dataset/save/figures/small_example_1\")\n",
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-09 08:42:08,222 | INFO | Epoch 0 ==> Opt Features train loss: 0.12484589219093323, val loss: 0.014547020196914673\n",
      "2024-04-09 08:42:08,223 | INFO | Epoch 0 ==> Opt Features train loss: 0.12484589219093323, val loss: 0.014547020196914673\n",
      "2024-04-09 08:42:49,596 | INFO | Epoch 1 ==> Opt Features train loss: 0.009358133189380169, val loss: 0.010507257655262947\n",
      "2024-04-09 08:42:49,597 | INFO | Epoch 1 ==> Opt Features train loss: 0.009358133189380169, val loss: 0.010507257655262947\n",
      "2024-04-09 08:43:14,310 | INFO | Epoch 0 ==> Opt Weights train loss: 0.03029516153037548, val loss: 0.021614646539092064\n",
      "2024-04-09 08:43:14,311 | INFO | Epoch 0 ==> Opt Weights train loss: 0.03029516153037548, val loss: 0.021614646539092064\n",
      "2024-04-09 08:43:36,874 | INFO | Epoch 1 ==> Opt Weights train loss: 0.017058193683624268, val loss: 0.017024029046297073\n",
      "2024-04-09 08:43:36,874 | INFO | Epoch 1 ==> Opt Weights train loss: 0.017058193683624268, val loss: 0.017024029046297073\n",
      "2024-04-09 08:44:11,014 | INFO | Epoch 2 ==> Opt Weights train loss: 0.01288222149014473, val loss: 0.011424420401453972\n",
      "2024-04-09 08:44:11,016 | INFO | Epoch 2 ==> Opt Weights train loss: 0.01288222149014473, val loss: 0.011424420401453972\n",
      "2024-04-09 08:44:38,601 | INFO | Epoch 3 ==> Opt Weights train loss: 0.008805216290056705, val loss: 0.00716796237975359\n",
      "2024-04-09 08:44:38,601 | INFO | Epoch 3 ==> Opt Weights train loss: 0.008805216290056705, val loss: 0.00716796237975359\n",
      "2024-04-09 08:45:06,776 | INFO | Epoch 4 ==> Opt Weights train loss: 0.007115009240806103, val loss: 0.006273019127547741\n",
      "2024-04-09 08:45:06,778 | INFO | Epoch 4 ==> Opt Weights train loss: 0.007115009240806103, val loss: 0.006273019127547741\n",
      "2024-04-09 08:45:36,863 | INFO | Epoch 5 ==> Opt Weights train loss: 0.0065276348032057285, val loss: 0.006130080670118332\n",
      "2024-04-09 08:45:36,864 | INFO | Epoch 5 ==> Opt Weights train loss: 0.0065276348032057285, val loss: 0.006130080670118332\n",
      "2024-04-09 08:46:04,086 | INFO | Epoch 6 ==> Opt Weights train loss: 0.00619597639888525, val loss: 0.006121021695435047\n",
      "2024-04-09 08:46:04,087 | INFO | Epoch 6 ==> Opt Weights train loss: 0.00619597639888525, val loss: 0.006121021695435047\n",
      "2024-04-09 08:46:31,964 | INFO | Epoch 7 ==> Opt Weights train loss: 0.006046607159078121, val loss: 0.0060849180445075035\n",
      "2024-04-09 08:46:31,965 | INFO | Epoch 7 ==> Opt Weights train loss: 0.006046607159078121, val loss: 0.0060849180445075035\n",
      "2024-04-09 08:47:01,057 | INFO | Epoch 8 ==> Opt Weights train loss: 0.005748575087636709, val loss: 0.005852243863046169\n",
      "2024-04-09 08:47:01,058 | INFO | Epoch 8 ==> Opt Weights train loss: 0.005748575087636709, val loss: 0.005852243863046169\n",
      "2024-04-09 08:47:33,002 | INFO | Epoch 9 ==> Opt Weights train loss: 0.005715709179639816, val loss: 0.005898105911910534\n",
      "2024-04-09 08:47:33,003 | INFO | Epoch 9 ==> Opt Weights train loss: 0.005715709179639816, val loss: 0.005898105911910534\n",
      "2024-04-09 08:48:22,771 | INFO | With seed: 8208 ===> criterium on test dataset: 0.17379022568220928\n"
     ]
    }
   ],
   "source": [
    "loss, model = trainer.train_and_test(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with a random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "dataset = data_loader.get_dataset(\"train\", False)\n",
    "trainset = data_loader.get_dataset('train', scaler=False)\n",
    "testset = data_loader.get_dataset('test', scaler=False)\n",
    "X_train = np.swapaxes(trainset.data_2d, 1, 2).reshape(trainset.data_2d.shape[0]*config['Freq'], -1)\n",
    "y_train = trainset.y.reshape(-1,)\n",
    "X_test = np.swapaxes(testset.data_2d, 1, 2).reshape(testset.data_2d.shape[0]*config['Freq'], -1)\n",
    "y_test = testset.y.reshape(-1,)\n",
    "\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MAPE = 13.98%\n"
     ]
    }
   ],
   "source": [
    "pred = rf.predict(X_test)\n",
    "from utils.metrics import MAPE\n",
    "\n",
    "print(f'Random Forest MAPE = {np.round(MAPE(y_test, pred)*100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini test with AutoPytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2024-04-09 09:00:31,041:Client-AutoPyTorch:d9647fc2-f63e-11ee-b927-4c796eb3bc8f:0] Time limit for a single run is higher than total time limit. Capping the limit for a single run to the total time given to SMAC (58.000000)\n",
      "[WARNING] [2024-04-09 09:00:31,042:Client-AutoPyTorch:d9647fc2-f63e-11ee-b927-4c796eb3bc8f:0] Capping the func_eval_time_limit_secs to 29 to have time for a least 2 models to ensemble.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/b98181/miniconda3/envs/new_env/lib/python3.9/site-packages/dask/dataframe/__init__.py:31: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/b98181/miniconda3/envs/new_env/lib/python3.9/site-packages/dask/dataframe/__init__.py:31: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/b98181/miniconda3/envs/new_env/lib/python3.9/site-packages/dask/dataframe/__init__.py:31: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/b98181/miniconda3/envs/new_env/lib/python3.9/site-packages/dask/dataframe/__init__.py:31: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/b98181/miniconda3/envs/new_env/lib/python3.9/site-packages/dask/dataframe/__init__.py:31: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/b98181/miniconda3/envs/new_env/lib/python3.9/site-packages/dask/dataframe/__init__.py:31: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/b98181/miniconda3/envs/new_env/lib/python3.9/site-packages/dask/dataframe/__init__.py:31: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/b98181/miniconda3/envs/new_env/lib/python3.9/site-packages/dask/dataframe/__init__.py:31: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/b98181/miniconda3/envs/new_env/lib/python3.9/site-packages/dask/dataframe/__init__.py:31: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/b98181/miniconda3/envs/new_env/lib/python3.9/site-packages/dask/dataframe/__init__.py:31: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/b98181/miniconda3/envs/new_env/lib/python3.9/site-packages/dask/dataframe/__init__.py:31: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/b98181/miniconda3/envs/new_env/lib/python3.9/site-packages/dask/dataframe/__init__.py:31: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/b98181/miniconda3/envs/new_env/lib/python3.9/site-packages/dask/dataframe/__init__.py:31: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/b98181/miniconda3/envs/new_env/lib/python3.9/site-packages/dask/dataframe/__init__.py:31: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/b98181/miniconda3/envs/new_env/lib/python3.9/site-packages/dask/dataframe/__init__.py:31: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/b98181/miniconda3/envs/new_env/lib/python3.9/site-packages/dask/dataframe/__init__.py:31: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/b98181/miniconda3/envs/new_env/lib/python3.9/site-packages/dask/dataframe/__init__.py:31: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/b98181/miniconda3/envs/new_env/lib/python3.9/site-packages/dask/dataframe/__init__.py:31: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/b98181/miniconda3/envs/new_env/lib/python3.9/site-packages/dask/dataframe/__init__.py:31: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/b98181/miniconda3/envs/new_env/lib/python3.9/site-packages/dask/dataframe/__init__.py:31: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "2024-04-09 09:01:25,430 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/b98181/miniconda3/envs/new_env/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 225, in read\n",
      "    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)\n",
      "tornado.iostream.StreamClosedError: Stream is closed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/b98181/miniconda3/envs/new_env/lib/python3.9/site-packages/distributed/worker.py\", line 1252, in heartbeat\n",
      "    response = await retry_operation(\n",
      "  File \"/home/b98181/miniconda3/envs/new_env/lib/python3.9/site-packages/distributed/utils_comm.py\", line 455, in retry_operation\n",
      "    return await retry(\n",
      "  File \"/home/b98181/miniconda3/envs/new_env/lib/python3.9/site-packages/distributed/utils_comm.py\", line 434, in retry\n",
      "    return await coro()\n",
      "  File \"/home/b98181/miniconda3/envs/new_env/lib/python3.9/site-packages/distributed/core.py\", line 1395, in send_recv_from_rpc\n",
      "    return await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/home/b98181/miniconda3/envs/new_env/lib/python3.9/site-packages/distributed/core.py\", line 1154, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/home/b98181/miniconda3/envs/new_env/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 236, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/home/b98181/miniconda3/envs/new_env/lib/python3.9/site-packages/distributed/comm/tcp.py\", line 142, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://127.0.0.1:33522 remote=tcp://127.0.0.1:46683>: Stream is closed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoPytorch MAPE = 12.4%\n"
     ]
    }
   ],
   "source": [
    "from autoPyTorch.api.tabular_regression import TabularRegressionTask\n",
    "\n",
    "X_train = X_train[-1000:]\n",
    "y_train = y_train[-1000:]\n",
    "X_test = X_test[:100]\n",
    "y_test = y_test[:100]\n",
    "\n",
    "api = TabularRegressionTask(seed=0,\n",
    "                                n_jobs=10,\n",
    "                                delete_tmp_folder_after_terminate=True)\n",
    "api.search(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    optimize_metric='root_mean_squared_error',\n",
    "    budget_type=\"epochs\",\n",
    "    min_budget=10,\n",
    "    max_budget=200,\n",
    "    total_walltime_limit=60,\n",
    "    func_eval_time_limit_secs=60*5, # 5 minues\n",
    "    enable_traditional_pipeline=True,\n",
    "    memory_limit=None        \n",
    ")\n",
    "y_pred = api.predict(X_test)\n",
    "print(f'AutoPytorch MAPE = {np.round(MAPE(y_test, y_pred)*100, 2)}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "new_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
